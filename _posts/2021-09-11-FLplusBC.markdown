---
layout: post
title: "Look Foward to BC + FL"
subtitle: "一些关于BC+FL的展望"
date: 2021-09-11
author: Krad
category: Blockchain
tags: blockchain FL
finished: true
published: true
---

## 前言

近两年不断有联邦学习（Federated Learning）与区块链技术(Blockchain Technology)相结合的工作出现。本人在这两方面均有涉猎，在这里想讨论下BC+FL在未来实际应用的可能性。本文主要从宏观的角度说说我自己的理解，基本上写到哪儿说到哪儿，定有疏忽还望海涵，当然任何形式的友好交流都是受欢迎的。

## Why BC + FL?

自从BC+FL的idea提出，相当一部分社区研究者们从各个方向给出了自己的结合方案。很多BC+FL的文章作者，往往会谈及BC与FL同为分布式系统，认为使用BC来保证FL中的信息交流与储存安全具有先天的优越性。这类文章通常会避开分析BC为FL系统带来的很多额外消耗，着重讨论BC如何安全且不可更改地保存FL中的学习模型，如何保证模型交换与传输的隐私性（privacy）与权威性（authenticity）。然而，大部分的这类文章更像是在讲一个美丽的故事，所谓的安全性是由区块链的数据冗余带来的，而隐私性等不过是使用了区块链中的非对称密钥技术而已，这些问题完全可以将区块链中的一小部分技术单独取出进行解决。相反，一味地套用区块链，反而会因为共识机制的引入为整个FL系统带来大量额外消耗。

就我个人而言，BC与FL相结合并没有什么先天优势可谈，BC技术最重要的一个特点就是去中心化。不幸的是，当今较为实用的FL系统通常是由一个中心服务器与复数个FL参与节点构成的，这恰恰与BC中提及的去中心化背道而驰。介于此，很大一部分的BC+FL工作在将两者结合时呈现出一种分离感，BC被当作一种API在使用，而BC与FL的底层原理与算法往往没有什么结合与适配。

![pic1](../img/bcfl/consensus-algo.png)

相较于谈论BC在FL上的先天优势，我更加认同BC+FL只是一次试错。现今阶段BC的理论技术趋于成熟，业界的讨论重心移至应用与落地，BC+FL本身也只是其中之一。就试错而言，应该允许BC+FL的初期研究工作不注重BC带来的额外消耗，而将目光聚焦于利用BC特性解决FL中的各种困境。但是回过头来，BC+FL的研究自2018算起（以Blockchained On-Device Federated Learning这篇文章为代表）也已经过了三年，随着FL领域的分类更加明了清晰，研究更加深入，BC+FL的研究也应该开始渐渐步入正轨了，是时候细化地讨论不同FL场景下BC加持的具体方式，深入到BC与FL的底层原理与算法，在算法层面上寻找二者结合的机会，用实际部署的实验结果进行分析与未来规划。


## 现存研究方向浅谈与评价

既然提到了细化研究，这里便从FL的不同分类开始说起。

FL自2017年被Google提出后才受到广泛关注，在此之前FL的别名有许多（e.g. Collaborative Learning， Distributed Optimization...）。根据最新的研究讨论（Advances and Open Problems in Federated Learning，2021版），社区普遍将FL分为三类，第一类为分布式学习或者叫并行学习（Datacenter distributed learning），第二类为组织间学习（Cross-silo federated learning），第三类为设备端学习（Cross-device federated learning）。其中第一类FL通过将数据中心的数据分配给FL参与者完成学习，其目的是为了提高模型学习的效率，与传统的分布式学习最为相近。第二类与第三类FL中的数据都是本来就存在于FL参与者上的，这些数据涉及私密性不能够直接地进行交流与汇聚，形成了一个又一个的数据孤岛，联邦学习通过传递本地训练得到的机器学习模型进行聚合实现机器学习模型的训练数据扩充与准确率提高。第二类与第三类FL的区别在于，组织间的联邦学习中参与者数量较少（通常5个就算比较多了）但是每个参与者上的数据较多,每个参与者会重复参与多次联邦学习的循环，可以进行纵向与横向的学习（自行百度）；而设备端上的FL参与节点为数量繁多的移动设备与物联网设备，每个参与节点的训练数据数量可能不同，质量也不相同，同时必须考虑每个设备节点的异质性，即不同的计算性能、电池电量、通信情况、网络情况等。由于设备节点的异质性，这些节点在参与联邦学习时表现出不稳定的特点（通常假设至少有5%的设备在一次联邦学习训练中不能完成任务）。

![pic1](../img/bcfl/classicFL.png)

想要利用BC的特性解决FL的问题，显然第三类FL的机会更多。对于第一类FL而言，区块链的加入会拖慢系统效率与其目的不符；对于第二类FL而言，区块链的安全性保证与区块链系统的参与节点数目有着很大关联，节点数目较少时区块链系统不稳定且远不及其他方法效率高。介于此，后文的讨论局限为BC在第三类即设备端FL的结合与应用。

现阶段的工作文献主要从三个方向为FL引入BC，概括如下：
* 数据安全存储与传输。
* 激励机制。
* 共识算法。

以下分点进行详细讨论。

### 数据安全存储与传输

对于FL系统中的数据安全分为模型的储存安全与模型的传输安全。

在FL中模型分为本地模型与全局模型，本地模型即FL参与节点自己用本地数据训练得到，而全局模型则是由中心服务器收集FL参与节点的本地模型后聚合而成。将本地模型作为交易信息（Transaction）储存在区块（Block）中，随着区块链的延伸，通过分布式的冗余存储，每个FL参与者上传的本地模型以及以此聚集的全局模型将不可篡改，这也使得任意一次模型训练都可以溯源，也即是模型存储安全的体现。这里存在一个争议点，即存储本地模型参数是否有意义。一部分人认为记录完整的模型参数进入区块中是有意义的，原因为两点1.联邦学习存在达到最优训练次数后继续学习，模型准确率开始下降的可能性，保留完整的模型数据便于回滚；2.保留完整的模型数据才能够实现溯源，为惩罚恶意节点以及奖励优质节点提供最直接的依据。另一部分人则认为模型参数文件占据大量存储空间（ResNet18的一个本地模型参数导出差不多30+MB），只需要保留节点参与联邦学习后上传本地模型的记录即可。事实上如果不保留模型参数，如前文所说，BC与FL始终是分离的，这种结合方式在Fabric上写个智能合约很快就能实现。为了减少模型参数带来的存储危机，很多文章喜欢提及存储模型的梯度以代替模型参数，或者优化学习模型框架使得只需保存部分模型参数，但我认为这样的提升都是不明显的，设备端的联邦学习需要经过上万次训练迭代，而且很多设备（移动设备与IoT设备）的存储空间极其有限。一种折中的方法是将模型参数作为交易信息的body，而参与训练的记录在在交易信息的head里，然后每隔一段时间选择性地剔除老旧区块中的交易信息的body，只保留head。

![pic1](../img/bcfl/transblock.png)

对于模型的传输安全，FL本地模型在作为交易信息进行传输时也会运用到区块链的密码学技术，能够在匿名情况下实现对模型的权威性保证。一些文章谈及的身份认证机制也可以被归为BC加持的传输安全成问题，其核心技术就是非对称密钥技术。以我拙见，大多数这类工作完全可以抛开BC不谈，直接深入到所涉及的密码学方法。总的来说，这个方可以再观望一下。

### 激励机制

激励机制是最早吸引研究者们为设备端FL引入BC的原因之一，因为设备端FL的早期主要困境之一就在于设备没有动机消耗计算与通信资源参与联邦学习。可惜的是，这方面的早期研究普遍太理想化了，不得不说，很多做FL研究的人可能真的从来没有实际部署过FL。早期这方面的研究都挺喜欢讲故事的，总结一下基本都是如下流程：考虑到区块链中的矿工进行挖矿可以获得奖励，希望利用这一激励机制来激励FL中的参与者，在其各种复杂的算法与公式推导后，往往会发现所谓的激励机制不过是使用区块链记录了下FL参与者的模型上传记录来实现最后的统计分配。这样地结合方式与区块链的挖矿激励几乎没有关系，太浮于表面了。那么FL还能从激励机制方向来引入BC吗？答案是肯定的，只是研究方向应该深入到区块链的挖矿机制中去，从共识算法的层面实现奖励的分配机制来实现激励。



### 共识算法

BC系统是去中心化的，在没有中心服务器（第三方可信中介）的情况下，想要维护区块链网络的稳定就需要共识机制。通俗的讲，共识机制就是要所有节点自发遵守同一种竞争机制去竞争完成一个任务（在PoW中为解决一Hash难题）然后选择出一个（或几个）节点来暂时维护网络与系统，也就是挖矿。这些通过竞争获得维护网络资格的节点同时也会获得奖励来激励更多的节点自发维护网络（在BitCoin中表现为在将自己的候选区块加入区块链中时写入本次挖矿的奖励），这便是BC激励机制的实质。一般情况下，BC的共识机制会引入大量额外的计算与通信资源消耗（PoW消耗算力，PoS，PBFT等会增加网络通信负载），这是引入BC到FL中亟待解决的问题。 

![pic1](../img/bcfl/mine.png)

将共识算法引入FL中，能够使得FL系统去中心化地运作以避免单点故障问题，并且摒弃第三方可信机构。其研究方向有很多，但我认为比较有趣的方向是构建PoUW（proof of useful work），即将挖矿的竞争任务由传统的Hash难题等修改为对FL系统运作有意义的任务。这里我只简单说说PoW共识算法下可能的两种相关模式。1）将FL设计为弱中心的系统框架，将中心服务器的权利下放，FL参与节点中有一些节点自发进行挖矿，挖矿包括收集并验证其它节点发布的本地模型的真实性与有效性，分配一次联邦学习循环的奖励，然后一旦在挖矿中胜出后可以将收集到的本地模型打包上传给中心服务器。2）所有节点FL地位均等，在单次FL循环的共识阶段，本地模型效果最好的节点获得全局模型的聚合权与更新权。要想将BC的共识机制与FL相结合，往往绕不开对本地模型的验证，这种验证包括本地模型的权威性（避免假冒顶替），本地模型的有效性（节点是否真的做了训练），本地模型的正确性（模型的质量好坏）。对于模型的权威性使用非对称密钥即可解决，而模型的有效性验证较为困难，但也有相应的可选方法（e.g. Intel的Software Guard Extensions可以证明设备确实执行过某一段代码），最难解决的问题其实是对于模型的正确率验证。对于模型的正确率验证，现阶段仍然缺乏高效可行的方法，最简单直接的办法便是用测试数据集计算本地模型的预测准确率，但是这会带来FL的模型偏移以及局部收敛等问题，同时需要节点能够任意读取其他节点发布的模型参数数据。现在FL领域经常喜欢提一个观点就是本地模型参数数据也能够透露节点的隐私性，认为需要使用HE与DP等方法给本地模型混淆后上传。这恰恰是阻碍FL中模型正确率验证的主要原因，然而我认为现今FL的实际应用需求还没有发展到太关心本地模型透露隐私的阶段，而且本地模型透露的所谓隐私很多时候只是用户的偏好信息，往往不能透露具体的私人信息。

当前阶段，如果想要继续深入BC共识算法在FL中的适配，可以细化FL的应用场景来寻找方向。对于系统节点可信度较高的FL场景，使用Raft形式的共识算法可以提高系统效率；对于并发需求不是太高的FL场景，可以引入PBFT形式的共识算法，提高系统稳定性以及方便与FL深入融合；对于着重考虑设备异质性而需建立异步更新的FL时，那么就可以考虑异步的共识机制去适配（Tangle等）。

## 总结

BC+FL的研究仍然处于初级阶段，结合方案层出不穷，但实际部署却基本没人关心。其原因在于1）投机者较多，很多人既不搞FL也不搞BC却依然能够进场，2）FL本身的研究才刚刚走上正轨，FL的定义太广泛，包含的模型种类太多，此前的分类一直模糊不清，根本不能进行系统的研究。3）缺乏公认的实验平台，这也是因为FL的研究发展缓慢，本身缺少大家都认可的实验平台来作为研究的基准。就目前来看，BC+FL的研究极其缺少真实部署的案例分析，我认为不管是从数据安全，激励机制，共识算法还是其它角度引入BC，都应该注重实际部署，最后落到系统效率或安全性与资源消耗的tradeoff上进行讨论分析。
